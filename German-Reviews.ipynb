{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Using only the text column in the csv file, predict 2 continous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_stop_words = stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raalucaa-attachments/training.txt', header=None)\n",
    "test = pd.read_csv('raalucaa-attachments/validation.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(x):\n",
    "    x.rename(mapper={0:'ID', 1:'target_1',2:'target_2',3:'text'}, axis=1, inplace=True)\n",
    "def new_csv(x,to_drop,new):\n",
    "    x.drop(columns=[i for i in to_drop]).to_csv(new, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols(df)\n",
    "rename_cols(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new datasets based on problem statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run only once\n",
    "\n",
    "# new_csv(df,['target_2'],'training_1.csv')\n",
    "# new_csv(df,['target_1'],'training_2.csv')\n",
    "\n",
    "# new_csv(test,['target_2'],'validation_1.csv')\n",
    "# new_csv(test,['target_1'],'validation_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.read_csv('training_1.csv')\n",
    "test_1 = pd.read_csv('validation_1.csv')\n",
    "train_2 = pd.read_csv('training_2.csv')\n",
    "test_2 = pd.read_csv('validation_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target_1</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119165</td>\n",
       "      <td>51.810067</td>\n",
       "      <td>Seit d Vase: \"Wenn ich kaputt gang, bringt das...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100377</td>\n",
       "      <td>51.918188</td>\n",
       "      <td>Haha bin au w isch der amig au so richtig lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109550</td>\n",
       "      <td>52.711074</td>\n",
       "      <td>isch d hiltl dachterrasse amne samstig viel bs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID   target_1                                               text\n",
       "0  119165  51.810067  Seit d Vase: \"Wenn ich kaputt gang, bringt das...\n",
       "1  100377  51.918188  Haha bin au w isch der amig au so richtig lang...\n",
       "2  109550  52.711074  isch d hiltl dachterrasse amne samstig viel bs..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.ID.nunique() / train_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x3cd7575748>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='target_1', data=train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2608     Händr e paar gueti summerlieder?? Danke im vor...\n",
       "15218    Kollegin het mir vom niklas verzellt den Segi ...\n",
       "13048    Blitzkaste zwüsched wald und rüti bhf.. (fast ...\n",
       "17274    Ich... Made... ?! NNÄÄÄÄII Gueti protein snack...\n",
       "2028     Min negste streich wird de si, dassi uf de tür...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.sample(5).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning / Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_ALPHANUMERIC = '[^a-zA-Z0-9äöüÄÖÜß]'\n",
    "TOKEN_ALPHABETIC = '[^a-zA-ZäöüÄÖÜß-]'\n",
    "mae_dict = {}\n",
    "seed = 0\n",
    "lr = 0.03\n",
    "stop = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(df, token, col):\n",
    "    '''\n",
    "    df : Dataframe\n",
    "    token : regex pattern to keep characters in text \n",
    "    col : name of column in Dataframe that contains the text\n",
    "    '''\n",
    "    corpus = []\n",
    "    for i in range(df.shape[0]):\n",
    "        text = df.iloc[i][col]\n",
    "        review =  re.sub(token,' ', text).lower() # keep only characters in token \n",
    "        corpus.append(review)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st Model Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clean_train = clean_words(train_1, TOKEN_ALPHANUMERIC, 'text')   #since we're using the same features for training for both tasks.\n",
    "target_1 = train_1.target_1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(max_features=8000)\n",
    "train_vec = cvec.fit_transform(get_clean_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_1 = {\n",
    " 'bagging_fraction': 0.9,\n",
    " 'feature_fraction': 0.5,\n",
    " 'learning_rate': 0.03,\n",
    " 'max_depth': -1,\n",
    " 'min_child_weight':5,\n",
    " 'min_split_gain': 0.03,\n",
    " 'num_iterations': 2000,\n",
    " 'num_leaves': 500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.9, feature_fraction=0.5, learning_rate=0.03,\n",
       "              min_child_weight=5, min_split_gain=0.03, n_estimators=2000,\n",
       "              num_leaves=500, random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgb1 = LGBMRegressor(random_state=seed, \n",
    "                     n_estimators = lgb_params_1['num_iterations'], \n",
    "                     learning_rate = lgb_params_1['learning_rate'],\n",
    "                     bagging_fraction = lgb_params_1['bagging_fraction'],\n",
    "                    feature_fraction = lgb_params_1['feature_fraction'],\n",
    "                    max_depth = lgb_params_1['max_depth'],\n",
    "                    min_child_weight = lgb_params_1['min_child_weight'],\n",
    "                    min_split_gain = lgb_params_1['min_split_gain'],\n",
    "                    num_leaves = lgb_params_1['num_leaves'])\n",
    "lgb1.fit(train_vec, target_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clean_test = clean_words(test_1, TOKEN_ALPHANUMERIC, 'text')  #since we're making inference on the same features for the 2 tasks.\n",
    "test_vec = cvec.transform(get_clean_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = lgb1.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4947130180618904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mean_absolute_error(p1, test_1.target_1))\n",
    "mae_dict['train_1_mae'] = (mean_absolute_error(p1, test_1.target_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_2 = train_2.target_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_2 = {\n",
    " 'bagging_fraction': 0.8,\n",
    " 'feature_fraction': 0.4,\n",
    " 'learning_rate': 0.01,\n",
    " 'max_depth': -1,\n",
    " 'min_child_weight': 20,\n",
    " 'min_split_gain': 0.05,\n",
    " 'num_iterations': 3000,\n",
    " 'num_leaves': 300\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Wall time: 2min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, feature_fraction=0.4, learning_rate=0.01,\n",
       "              min_child_weight=20, min_split_gain=0.05, n_estimators=3000,\n",
       "              num_leaves=300, random_state=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgb2 = LGBMRegressor(random_state=seed, \n",
    "                     n_estimators = lgb_params_2['num_iterations'], \n",
    "                     learning_rate = lgb_params_2['learning_rate'],\n",
    "                     bagging_fraction = lgb_params_2['bagging_fraction'],\n",
    "                    feature_fraction = lgb_params_2['feature_fraction'],\n",
    "                    max_depth = lgb_params_2['max_depth'],\n",
    "                    min_child_weight = lgb_params_2['min_child_weight'],\n",
    "                    min_split_gain = lgb_params_2['min_split_gain'],\n",
    "                    num_leaves = lgb_params_2['num_leaves'])\n",
    "lgb2.fit(train_vec, target_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = lgb2.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6201840709320485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mean_absolute_error(p2, test_2.target_2))\n",
    "mae_dict['train_2_mae'] = (mean_absolute_error(p2, test_2.target_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of absolute error for the 2 target features = 0.5574485444969695\n"
     ]
    }
   ],
   "source": [
    "print('Mean of absolute error for the 2 target features = {}'.format(pd.Series(mae_dict).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd Model Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold Cross validation LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_mae_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFOLD_LGBM(train, target, val, params_dict, k=5, early=stop):\n",
    "    '''\n",
    "    train : Train array\n",
    "    target : Prediction array\n",
    "    val : Validationa array\n",
    "    params_dict : dictionary of parameters to pass to lightgbm \n",
    "    k : number of splits to perform cross validation\n",
    "    early : early_stop_rounds parameter \n",
    "    \n",
    "    return : Prediction result on validation array \n",
    "    '''\n",
    "    \n",
    "    fold = KFold(n_splits = k, shuffle=True, random_state=seed)\n",
    "    prediction = []\n",
    "    err = []\n",
    "    i = 1 \n",
    "    X = pd.DataFrame(train)\n",
    "    y = pd.DataFrame(target)\n",
    "    for train_index, test_index in fold.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]   \n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        m = LGBMRegressor(random_state=seed, \n",
    "                     n_estimators = params_dict['num_iterations'], \n",
    "                     learning_rate = params_dict['learning_rate'],\n",
    "                     bagging_fraction = params_dict['bagging_fraction'],\n",
    "                    feature_fraction = params_dict['feature_fraction'],\n",
    "                    max_depth = params_dict['max_depth'],\n",
    "                    min_child_weight = params_dict['min_child_weight'],\n",
    "                    min_split_gain = params_dict['min_split_gain'],\n",
    "                    num_leaves = params_dict['num_leaves'],\n",
    "                    eval_metric='mae')\n",
    "        \n",
    "        #m = LGBMRegressor(n_estimators=n_estimators, eval_metric='mae',learning_rate=lr, random_seed=seed, use_best_model=True )\n",
    "        m.fit(X_train,y_train, eval_set=[(X_train,y_train),(X_test, y_test)], early_stopping_rounds=early, verbose=100)\n",
    "        preds = m.predict(X_test)\n",
    "        print(\"err: \",mean_absolute_error(y_test,preds))\n",
    "        err.append(mean_absolute_error(y_test,preds))\n",
    "        p = m.predict(val)\n",
    "        prediction.append(p)\n",
    "        i+=1\n",
    "    print('Mean of absolute error for {} folds = {}'.format(k,np.mean(err)))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 0.307795\tvalid_1's l2: 0.444674\n",
      "[200]\ttraining's l2: 0.213831\tvalid_1's l2: 0.426988\n",
      "Early stopping, best iteration is:\n",
      "[176]\ttraining's l2: 0.228188\tvalid_1's l2: 0.426838\n",
      "err:  0.4980951057670948\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 0.306865\tvalid_1's l2: 0.462839\n",
      "[200]\ttraining's l2: 0.212412\tvalid_1's l2: 0.44941\n",
      "Early stopping, best iteration is:\n",
      "[160]\ttraining's l2: 0.237445\tvalid_1's l2: 0.448804\n",
      "err:  0.5075377505480017\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 0.305351\tvalid_1's l2: 0.464696\n",
      "[200]\ttraining's l2: 0.212488\tvalid_1's l2: 0.440493\n",
      "[300]\ttraining's l2: 0.180169\tvalid_1's l2: 0.440689\n",
      "Early stopping, best iteration is:\n",
      "[241]\ttraining's l2: 0.195593\tvalid_1's l2: 0.440039\n",
      "err:  0.5033097218619956\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 0.301059\tvalid_1's l2: 0.477816\n",
      "[200]\ttraining's l2: 0.208503\tvalid_1's l2: 0.454371\n",
      "[300]\ttraining's l2: 0.176623\tvalid_1's l2: 0.454577\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttraining's l2: 0.195401\tvalid_1's l2: 0.453566\n",
      "err:  0.5058372939042386\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 0.302143\tvalid_1's l2: 0.489519\n",
      "[200]\ttraining's l2: 0.209792\tvalid_1's l2: 0.468335\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's l2: 0.210299\tvalid_1's l2: 0.468264\n",
      "err:  0.5117504488550881\n",
      "Mean of absolute error for 5 folds = 0.5053060641872837\n",
      "Wall time: 5min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test1_kfold = KFOLD_LGBM(train_vec, target_1, test_vec, lgb_params_1, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49024951105972786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mean_absolute_error(test_1.target_1, np.mean(test1_kfold, 0)))  # Found the mean prediction of the folds\n",
    "kfold_mae_dict['train_1_mae'] = mean_absolute_error(test_1.target_1, np.mean(test1_kfold, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 1.00988\tvalid_1's l2: 1.1314\n",
      "[200]\ttraining's l2: 0.723211\tvalid_1's l2: 0.916473\n",
      "[300]\ttraining's l2: 0.582915\tvalid_1's l2: 0.827335\n",
      "[400]\ttraining's l2: 0.501654\tvalid_1's l2: 0.787255\n",
      "[500]\ttraining's l2: 0.448956\tvalid_1's l2: 0.768752\n",
      "[600]\ttraining's l2: 0.412709\tvalid_1's l2: 0.76055\n",
      "[700]\ttraining's l2: 0.385267\tvalid_1's l2: 0.756925\n",
      "[800]\ttraining's l2: 0.364302\tvalid_1's l2: 0.756378\n",
      "[900]\ttraining's l2: 0.347882\tvalid_1's l2: 0.756743\n",
      "Early stopping, best iteration is:\n",
      "[822]\ttraining's l2: 0.360346\tvalid_1's l2: 0.756177\n",
      "err:  0.6385566256204488\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 1.00818\tvalid_1's l2: 1.12798\n",
      "[200]\ttraining's l2: 0.722864\tvalid_1's l2: 0.916582\n",
      "[300]\ttraining's l2: 0.585032\tvalid_1's l2: 0.830003\n",
      "[400]\ttraining's l2: 0.504458\tvalid_1's l2: 0.789101\n",
      "[500]\ttraining's l2: 0.452634\tvalid_1's l2: 0.770684\n",
      "[600]\ttraining's l2: 0.416409\tvalid_1's l2: 0.76347\n",
      "[700]\ttraining's l2: 0.388889\tvalid_1's l2: 0.761453\n",
      "[800]\ttraining's l2: 0.367436\tvalid_1's l2: 0.760766\n",
      "[900]\ttraining's l2: 0.350813\tvalid_1's l2: 0.7612\n",
      "Early stopping, best iteration is:\n",
      "[800]\ttraining's l2: 0.367436\tvalid_1's l2: 0.760766\n",
      "err:  0.6417467673772351\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 1.0086\tvalid_1's l2: 1.1345\n",
      "[200]\ttraining's l2: 0.725978\tvalid_1's l2: 0.921335\n",
      "[300]\ttraining's l2: 0.58627\tvalid_1's l2: 0.835445\n",
      "[400]\ttraining's l2: 0.503814\tvalid_1's l2: 0.795441\n",
      "[500]\ttraining's l2: 0.450659\tvalid_1's l2: 0.776872\n",
      "[600]\ttraining's l2: 0.413857\tvalid_1's l2: 0.770049\n",
      "[700]\ttraining's l2: 0.386259\tvalid_1's l2: 0.766403\n",
      "[800]\ttraining's l2: 0.364907\tvalid_1's l2: 0.765793\n",
      "[900]\ttraining's l2: 0.348058\tvalid_1's l2: 0.7658\n",
      "Early stopping, best iteration is:\n",
      "[852]\ttraining's l2: 0.355507\tvalid_1's l2: 0.765569\n",
      "err:  0.6414669676404078\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 1.0126\tvalid_1's l2: 1.09585\n",
      "[200]\ttraining's l2: 0.729666\tvalid_1's l2: 0.888044\n",
      "[300]\ttraining's l2: 0.591652\tvalid_1's l2: 0.801849\n",
      "[400]\ttraining's l2: 0.508086\tvalid_1's l2: 0.758713\n",
      "[500]\ttraining's l2: 0.453765\tvalid_1's l2: 0.73916\n",
      "[600]\ttraining's l2: 0.416173\tvalid_1's l2: 0.731514\n",
      "[700]\ttraining's l2: 0.387989\tvalid_1's l2: 0.729147\n",
      "[800]\ttraining's l2: 0.366421\tvalid_1's l2: 0.7291\n",
      "Early stopping, best iteration is:\n",
      "[767]\ttraining's l2: 0.373023\tvalid_1's l2: 0.728899\n",
      "err:  0.6258588326162348\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 1.00373\tvalid_1's l2: 1.15764\n",
      "[200]\ttraining's l2: 0.71826\tvalid_1's l2: 0.936082\n",
      "[300]\ttraining's l2: 0.578474\tvalid_1's l2: 0.844602\n",
      "[400]\ttraining's l2: 0.496246\tvalid_1's l2: 0.802123\n",
      "[500]\ttraining's l2: 0.444024\tvalid_1's l2: 0.781306\n",
      "[600]\ttraining's l2: 0.407561\tvalid_1's l2: 0.771455\n",
      "[700]\ttraining's l2: 0.379869\tvalid_1's l2: 0.767476\n",
      "[800]\ttraining's l2: 0.357806\tvalid_1's l2: 0.765528\n",
      "[900]\ttraining's l2: 0.341206\tvalid_1's l2: 0.764511\n",
      "[1000]\ttraining's l2: 0.328822\tvalid_1's l2: 0.763952\n",
      "[1100]\ttraining's l2: 0.319897\tvalid_1's l2: 0.764035\n",
      "Early stopping, best iteration is:\n",
      "[1006]\ttraining's l2: 0.328202\tvalid_1's l2: 0.76393\n",
      "err:  0.6394646871904202\n",
      "Mean of absolute error for 5 folds = 0.6374187760889493\n",
      "Wall time: 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test2_kfold = KFOLD_LGBM(train_vec, target_2, test_vec, lgb_params_2, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6186940673154071"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mean_absolute_error(test_2.target_2, np.mean(test2_kfold, 0)))  # Found the mean prediction of the folds\n",
    "kfold_mae_dict['train_2_mae'] = mean_absolute_error(test_2.target_2, np.mean(test2_kfold, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of absolute error for the 2 target features = 0.5544717891875675\n"
     ]
    }
   ],
   "source": [
    "print('Mean of absolute error for the 2 target features = {}'.format(pd.Series(kfold_mae_dict).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blending of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_mae_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def (pred1, pred2, factor):\n",
    "    ''' \n",
    "    pred1 : prediction to blend\n",
    "    pred2 : prediction to blend\n",
    "    factor : percentage to use in blending pred1 and pred2\n",
    "    \n",
    "    return : blended results of pred1 and pred2\n",
    "    '''\n",
    "    result = (pred1*pred2) + (pred2*(1-factor))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_test_1 = blend(p1, np.mean(test1_kfold,0), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48930398292253247"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mean_absolute_error(test_1.target_1, blended_test_1))  # Found the mean prediction of the folds\n",
    "blend_mae_dict['test_1_mae'] = mean_absolute_error(test_1.target_1, blended_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_test_2 = blend(p2, np.mean(test2_kfold,0), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6163358128855457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mean_absolute_error(test_2.target_2, blended_test_2))  # Found the mean prediction of the folds\n",
    "blend_mae_dict['test_2_mae'] = mean_absolute_error(test_2.target_2, blended_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of absolute error for the 2 target features = 0.5528198979040391\n"
     ]
    }
   ],
   "source": [
    "print('Mean of absolute error for the 2 target features = {}'.format(pd.Series(blend_mae_dict).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
